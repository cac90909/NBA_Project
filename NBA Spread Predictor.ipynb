{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "import statsmodels.api as sm\n",
    "from scipy import stats\n",
    "from bs4 import BeautifulSoup\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "from datetime import datetime, timedelta\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "headings = ['Reserves',\n",
    " 'MP',\n",
    " 'FG',\n",
    " 'FGA',\n",
    " 'FG%',\n",
    " '3P',\n",
    " '3PA',\n",
    " '3P%',\n",
    " 'FT',\n",
    " 'FTA',\n",
    " 'FT%',\n",
    " 'ORB',\n",
    " 'DRB',\n",
    " 'TRB',\n",
    " 'AST',\n",
    " 'STL',\n",
    " 'BLK',\n",
    " 'TOV',\n",
    " 'PF',\n",
    " 'PTS',\n",
    " '+/-']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to gather the basic data for any team.\n",
    "#Returns data in a dataframe object\n",
    "\n",
    "\n",
    "def gatherTeamData(team_abr):\n",
    "    #First, their schedule\n",
    "    source = requests.get(\"https://www.basketball-reference.com/teams/\" + team_abr + \"/2020_games.html\").text\n",
    "    soup = BeautifulSoup(source,'lxml')\n",
    "    #Gets links to all their games\n",
    "    table = soup.find(\"table\").find(\"tbody\")\n",
    "    list_of_links = []\n",
    "    for row in table.find_all(\"tr\"): #find every tabel row\n",
    "        for data_point in row.find_all(\"td\"): #for every tabel row, find every data point\n",
    "            if (data_point[\"data-stat\"] == \"box_score_text\"):\n",
    "                link = \"https://www.basketball-reference.com/\"\n",
    "                link = link + data_point.a.get(\"href\")\n",
    "                list_of_links.append(link)\n",
    "    #Extracting the Dates from the links\n",
    "    list_of_dates = list(link[48:56] for link in list_of_links)\n",
    "    format_list_of_dates = list()\n",
    "    datetime_list = list()\n",
    "    for single_date in list_of_dates:\n",
    "        year = single_date[0:4]\n",
    "        month = single_date[4:6]\n",
    "        day = single_date[6:]\n",
    "        format_date = year + \"-\" + month + \"-\" + day\n",
    "        format_list_of_dates.append(format_date)\n",
    "        datetime_list.append(datetime.strptime(format_date,\"%Y-%m-%d\"))\n",
    "    #Keeping only the dates that haven't happend yet\n",
    "    yesterday = datetime.now() - timedelta(days=3) \n",
    "    trimmed_date_list = list()\n",
    "    for date in datetime_list:\n",
    "        if date < yesterday:\n",
    "            trimmed_date_list.append(date)\n",
    "    #Trimming our list of links down to only links to games that have happend\n",
    "    trimmed_list_of_links = list()\n",
    "    trimmed_list_of_links = list_of_links[:len(trimmed_date_list)]\n",
    "    #Translating datatime objects back into Strings\n",
    "    trimmed_string_dates = list()\n",
    "    for date in trimmed_date_list:\n",
    "        trimmed_string_dates.append(date.strftime(\"%m-%d-%Y\"))\n",
    "    #Gathering basic stats from the links \n",
    "    team_stats = []\n",
    "    for link in trimmed_list_of_links:\n",
    "        source = requests.get(link).text\n",
    "        soup = BeautifulSoup(source,'lxml')\n",
    "        team_stats_html = soup.find(\"table\", id=\"box-\"+ team_abr + \"-game-basic\").find(\"tfoot\").find(\"tr\")\n",
    "        iteration_data = []\n",
    "        for data_entry in team_stats_html.find_all(\"td\"):\n",
    "            iteration_data.append(data_entry.text)\n",
    "        team_stats.append(iteration_data)\n",
    "    #Creating DataFrame Obj\n",
    "    team_stats_df = pd.DataFrame(team_stats, index = trimmed_string_dates,\n",
    "                                   columns = headings[1:] )\n",
    "    return team_stats_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gathering the teams opponents\n",
    "\n",
    "def gatherOpponentData(team_abr):\n",
    "    #First, their schedule\n",
    "    source = requests.get(\"https://www.basketball-reference.com/teams/\" + team_abr + \"/2020_games.html\").text\n",
    "    soup = BeautifulSoup(source,'lxml')\n",
    "    #Gets links to all their games\n",
    "    table = soup.find(\"table\").find(\"tbody\")\n",
    "    list_of_links = []\n",
    "    for row in table.find_all(\"tr\"): #find every tabel row\n",
    "        for data_point in row.find_all(\"td\"): #for every tabel row, find every data point\n",
    "            if (data_point[\"data-stat\"] == \"box_score_text\"):\n",
    "                link = \"https://www.basketball-reference.com/\"\n",
    "                link = link + data_point.a.get(\"href\")\n",
    "                list_of_links.append(link)\n",
    "    #Extracting the Dates from the links\n",
    "    list_of_dates = list(link[48:56] for link in list_of_links)\n",
    "    format_list_of_dates = list()\n",
    "    datetime_list = list()\n",
    "    for single_date in list_of_dates:\n",
    "        year = single_date[0:4]\n",
    "        month = single_date[4:6]\n",
    "        day = single_date[6:]\n",
    "        format_date = year + \"-\" + month + \"-\" + day\n",
    "        format_list_of_dates.append(format_date)\n",
    "        datetime_list.append(datetime.strptime(format_date,\"%Y-%m-%d\"))\n",
    "    #Keeping only the dates that haven't happend yet\n",
    "    yesterday = datetime.now() - timedelta(days=3) \n",
    "    trimmed_date_list = list()\n",
    "    for date in datetime_list:\n",
    "        if date < yesterday:\n",
    "            trimmed_date_list.append(date)\n",
    "    #Translating datatime objects back into Strings\n",
    "    trimmed_string_dates = list()\n",
    "    for date in trimmed_date_list:\n",
    "        trimmed_string_dates.append(date.strftime(\"%m-%d-%Y\"))\n",
    "    #Trimming our list of links down to only links to games that have happend\n",
    "    trimmed_list_of_links = list()\n",
    "    trimmed_list_of_links = list_of_links[:len(trimmed_string_dates)]\n",
    "    #Gathering basic stats from the links\n",
    "    opponent_stats = []\n",
    "    for link in trimmed_list_of_links:\n",
    "        source = requests.get(link).text\n",
    "        soup = BeautifulSoup(source,'lxml')\n",
    "        for div in soup.find_all(\"div\", class_=\"overthrow table_container\"):\n",
    "            if(div[\"id\"].find(team_abr) == -1):\n",
    "                if(div[\"id\"].find(\"q1\") == -1 and div[\"id\"].find(\"q2\") == -1 and div[\"id\"].find(\"h1\") == -1\n",
    "                  and div[\"id\"].find(\"q3\") == -1 and div[\"id\"].find(\"q4\") == -1 and div[\"id\"].find(\"h2\") == -1\n",
    "                  and div[\"id\"].find(\"advanced\") == -1):\n",
    "                    table_foot = div.find(\"table\").find(\"tfoot\")\n",
    "                    iteration_data = []\n",
    "                    for data_point in table_foot.find_all(\"td\"):\n",
    "                        iteration_data.append(data_point.text)\n",
    "                    opponent_stats.append(iteration_data)\n",
    "    opponent_stats_df = pd.DataFrame(opponent_stats[:len(trimmed_string_dates)], index = trimmed_string_dates, \n",
    "                                      columns = headings[1:])\n",
    "    return opponent_stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Analyze the data from constructed dataframes\n",
    "\n",
    "def analyzeData(t1_df,t1_opp_df,t2_df,t2_opp_df):\n",
    "    #Defining variables\n",
    "    t1_x = t1_df[['FGA','FG%','3PA','3P%','FT%','STL','PF']]\n",
    "    t2_x = t2_df[['FGA','FG%','3PA','3P%','FT%','STL','PF']]\n",
    "    t1_y = t1_df[\"PTS\"].values\n",
    "    t2_y = t2_df[\"PTS\"].values\n",
    "    t1_opp_stats = t1_opp_df[['FGA','FG%','3PA','3P%','FT%','STL','PF']]\n",
    "    t2_opp_stats = t2_opp_df[['FGA','FG%','3PA','3P%','FT%','STL','PF']] \n",
    "    #Core inputs\n",
    "    t1_core_input = (t1_x.mean() + t2_opp_stats.mean())/2 \n",
    "    t2_core_input = (t2_x.mean() + t1_opp_stats.mean())/2\n",
    "     #Translating string df to int df\n",
    "    core_stats = ['FGA','FG%','3PA','3P%','FT%','STL','PF']\n",
    "    t1_avg = []\n",
    "    t1_opp_avg = []\n",
    "    t2_avg = []\n",
    "    t2_opp_avg = []\n",
    "    t1_avg.append\n",
    "    for stat in core_stats:\n",
    "        t1_avg.append(pd.to_numeric(t1_x[stat]).mean())\n",
    "        t1_opp_avg.append(pd.to_numeric(t1_opp_stats[stat]).mean())\n",
    "        t2_avg.append(pd.to_numeric(t2_x[stat]).mean())\n",
    "        t2_opp_avg.append(pd.to_numeric(t2_opp_stats[stat]).mean())\n",
    "    #Translating string core input into int core input\n",
    "    t1_core_input = []\n",
    "    t2_core_input = []\n",
    "    c = 0\n",
    "    for stat in core_stats:\n",
    "        t1_core_input.append((t1_avg[c] + t2_opp_avg[c])/2)\n",
    "        t2_core_input.append((t2_avg[c] + t1_opp_avg[c])/2)\n",
    "        c = c + 1\n",
    "    #Translatng string x and y into int x and y\n",
    "    t1_x_num = []\n",
    "    t2_x_num = []\n",
    "    for stat in core_stats:\n",
    "        t1_x_num.append(pd.to_numeric(t1_x[stat]))\n",
    "        t2_x_num.append(pd.to_numeric(t2_x[stat]))\n",
    "    t1_y_num = pd.to_numeric(t1_y)\n",
    "    t2_y_num = pd.to_numeric(t2_y)\n",
    "    t1_x_num = np.asarray(t1_x_num).transpose()\n",
    "    t2_x_num = np.asarray(t2_x_num).transpose()\n",
    "    #Creating the models\n",
    "    t1_x_train, t1_x_test, t1_y_train, t1_y_test = train_test_split(t1_x_num, t1_y_num, test_size = 0.2, random_state = 0)\n",
    "    t1_reg = LinearRegression()\n",
    "    t1_reg.fit(t1_x_train,t1_y_train)\n",
    "    t2_x_train, t2_x_test, t2_y_train, t2_y_test = train_test_split(t2_x_num, t2_y_num, test_size = 0.2, random_state = 0)\n",
    "    t2_reg = LinearRegression()\n",
    "    t2_reg.fit(t2_x_train,t2_y_train)\n",
    "    #Creating predictions\n",
    "    t1_pred = t1_reg.predict(np.asarray(t1_core_input).reshape(1,-1))[0]\n",
    "    t2_pred = t2_reg.predict(np.asarray(t2_core_input).reshape(1,-1))[0]\n",
    "    #Calculating spread\n",
    "    spread = t1_pred - t2_pred\n",
    "    return t1_pred, t2_pred, spread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A function to call our previously defined functions \n",
    "\n",
    "def gatherAndAnalyze(team_1_abr,team_2_abr):\n",
    "    team_1_df = gatherTeamData(team_1_abr)\n",
    "    team_2_df = gatherTeamData(team_2_abr)\n",
    "    team_1_opp_df = gatherOpponentData(team_1_abr)\n",
    "    team_2_opp_df = gatherOpponentData(team_2_abr)\n",
    "    t1_pred,t2_pred,spread = analyzeData(team_1_df,team_1_opp_df,team_2_df,team_2_opp_df)\n",
    "    print(team_1_abr, \" will score \", round(t1_pred,2))\n",
    "    print(team_2_abr, \" will score \", round(t2_pred,2))\n",
    "    print(\"Resulting in a \", round(spread,2), \"spread \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function to automate the calling of 'gatherAndAnalyze'\n",
    "# This function will predict all the NBA games played on current day\n",
    "\n",
    "def predictGamesToday():\n",
    "    \n",
    "    #Map of numerical to abbreviated months\n",
    "    months = {\n",
    "    1: \"january\",\n",
    "    2: \"february\",\n",
    "    3: \"march\",\n",
    "    4: \"april\",\n",
    "    5: \"may\",\n",
    "    6: \"june\",\n",
    "    7: \"july\",\n",
    "    8: \"august\",\n",
    "    9: \"september\",\n",
    "    10: \"october\",\n",
    "    11: \"november\",\n",
    "    12: \"december\"\n",
    "    }\n",
    "    #Assembling the link to today's games\n",
    "    currentMonth = months[datetime.now().month]\n",
    "    month = datetime.now().month\n",
    "    linkToThisMonthsGames = \"https://www.basketball-reference.com/leagues/NBA_\" + str(datetime.now().year) + \"_games-\" + currentMonth + \".html\"\n",
    "    #Getting the text from the link\n",
    "    source = requests.get('https://www.basketball-reference.com/leagues/NBA_2020_games-march.html').text\n",
    "    soup = BeautifulSoup(source,'lxml')\n",
    "    #Getting the list of teams playing today\n",
    "    listGames = []\n",
    "    listTeams = []\n",
    "    todayStr = currentMonth[0].upper() + currentMonth[1:3]+ datetime.now().strftime(\" %#d, %y\") + \"20\"\n",
    "    for row in soup.tbody.find_all(\"tr\"):\n",
    "        if(row.a.text.find(todayStr) != -1):\n",
    "            for data_point in row.find_all(\"td\"):\n",
    "                listTeams.append(str(data_point.find(\"a\")))\n",
    "    listTeams[:] = (value for value in listTeams if value != 'None')\n",
    "    slicer = lambda x: x[16:19]  #[16:19] in link contains team abbrev.\n",
    "    listTeams = list(map(slicer,listTeams))\n",
    "    #Calling gatherAndAnalyze for all the teams playing today\n",
    "    for x in range(0,len(listTeams),2):\n",
    "        gameList = []\n",
    "        team_1_abr = listTeams[x]\n",
    "        team_2_abr = listTeams[x+1]\n",
    "        gatherAndAnalyze(team_1_abr, team_2_abr)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DET  will score  106.08\n",
      "PHI  will score  110.73\n",
      "Resulting in a  -4.65 spread \n",
      "\n",
      "NYK  will score  111.64\n",
      "ATL  will score  111.56\n",
      "Resulting in a  0.07 spread \n",
      "\n",
      "CHO  will score  104.49\n",
      "MIA  will score  114.08\n",
      "Resulting in a  -9.58 spread \n",
      "\n",
      "DEN  will score  110.93\n",
      "DAL  will score  113.7\n",
      "Resulting in a  -2.78 spread \n",
      "\n",
      "UTA  will score  112.18\n",
      "OKC  will score  110.66\n",
      "Resulting in a  1.52 spread \n",
      "\n",
      "NOP  will score  114.82\n",
      "SAC  will score  110.71\n",
      "Resulting in a  4.1 spread \n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictGamesToday()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
